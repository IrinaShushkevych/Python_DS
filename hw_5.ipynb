{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d326586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093d5a4",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea2a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'min_x',\n",
    "    'min_y',\n",
    "    'min_z',\n",
    "    'max_x',\n",
    "    'max_y',\n",
    "    'max_z',\n",
    "    'mean_x',\n",
    "    'mean_y',\n",
    "    'mean_z',\n",
    "    'std_x',\n",
    "    'std_y',\n",
    "    'std_z',\n",
    "    'median_x',\n",
    "    'median_y',\n",
    "    'median_z',\n",
    "    'index_min_x',\n",
    "    'index_min_y',\n",
    "    'index_min_z',\n",
    "    'index_max_x',\n",
    "    'index_max_y',\n",
    "    'index_max_z',\n",
    "    'skew_x',\n",
    "    'skew_y',\n",
    "    'skew_z',\n",
    "    'kurtosis_x',\n",
    "    'kurtosis_y',\n",
    "    'kurtosis_z',\n",
    "    'variance_x',\n",
    "    'variance_y',\n",
    "    'variance_z',\n",
    "    'correlation_x_y',\n",
    "    'correlation_x_z',\n",
    "    'correlation_y_z',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d3c5ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_features(data):\n",
    "    res = np.array([])\n",
    "    res = np.concatenate((res, data.min(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.max(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.mean(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.std(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.median(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.idxmin(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.idxmax(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.skew(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.kurt(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.var(axis=0).values), axis=0)\n",
    "    corr = data.corr()\n",
    "    corr['accelerometer_X']['accelerometer_Y'], corr['accelerometer_X']['accelerometer_Z'], corr['accelerometer_Y']['accelerometer_Z']\n",
    "    res = np.concatenate((res, [corr['accelerometer_X']['accelerometer_Y'], corr['accelerometer_X']['accelerometer_Z'], corr['accelerometer_Y']['accelerometer_Z']]), axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1bc39228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_features_part(data):\n",
    "    res = np.array([])\n",
    "    res = np.concatenate((res, data.min(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.max(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.mean(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.std(axis=0).values), axis=0)\n",
    "    res = np.concatenate((res, data.median(axis=0).values), axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "0b647eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    activities = os.listdir(path)\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(activities)):\n",
    "        dir_name = os.path.join(path, activities[i])\n",
    "        X_p = []\n",
    "        for file in os.listdir(dir_name):\n",
    "            if file.split('.')[-1] == 'csv':\n",
    "                data = pd.read_csv(os.path.join(dir_name, file))\n",
    "                X_p.append(data.values[0]) \n",
    "        y_p =[i]*len(X_p)\n",
    "        y = [*y, *y_p]\n",
    "        X = [*X, *X_p]\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "77d0856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_features(path):\n",
    "    activities = os.listdir(path)\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(activities)):\n",
    "        dir_name = os.path.join(path, activities[i])\n",
    "        X_p = []\n",
    "        for file in os.listdir(dir_name):\n",
    "            if file.split('.')[-1] == 'csv':\n",
    "                data = pd.read_csv(os.path.join(dir_name, file))\n",
    "                X_p.append(prepare_data_features(data)) \n",
    "        y_p =[i]*len(X_p)\n",
    "        y = [*y, *y_p]\n",
    "        X = [*X, *X_p]\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "d1abf4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_features_part(path):\n",
    "    activities = os.listdir(path)\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(activities)):\n",
    "        dir_name = os.path.join(path, activities[i])\n",
    "        X_p = []\n",
    "        for file in os.listdir(dir_name):\n",
    "            if file.split('.')[-1] == 'csv':\n",
    "                data = pd.read_csv(os.path.join(dir_name, file))\n",
    "                X_p.append(prepare_data_features_part(data)) \n",
    "        y_p =[i]*len(X_p)\n",
    "        y = [*y, *y_p]\n",
    "        X = [*X, *X_p]\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "af136ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(prefix, X, y):\n",
    "    with open(f'data_X_{prefix}.pickle', 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "    with open(f'data_y_{prefix}.pickle', 'wb') as f:\n",
    "        pickle.dump(y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b420163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(prefix):\n",
    "    with open(f'data_X_{prefix}.pickle', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    with open(f'data_y_{prefix}.pickle', 'rb') as f:\n",
    "        y = pickle.load(f)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "da191371",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = read_data('data')\n",
    "save_data('simple', X, y)\n",
    "X, y = read_data_features_part('data')\n",
    "save_data('feature_half', X, y)\n",
    "X, y = read_data_features('data')\n",
    "save_data('feature', X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f605a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data('simple')\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y, train_size=0.2, random_state=42)\n",
    "X, y = load_data('feature_half')\n",
    "X_test_fh, X_train_fh, y_test_fh, y_train_fh = train_test_split(X, y, train_size=0.2, random_state=42)\n",
    "X, y = load_data('feature')\n",
    "X_test_f, X_train_f, y_test_f, y_train_f = train_test_split(X, y, train_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d88c2",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d78868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(X_test, X_train, y_test, y_train):\n",
    "    svm_ovo_rbf = SVC(decision_function_shape='ovo', kernel='rbf').fit(X_train, y_train)\n",
    "    svm_ovo_rbf_gamma = SVC(decision_function_shape='ovo', kernel='rbf', gamma=0.005).fit(X_train, y_train)\n",
    "    svm_ovo_linear = SVC(decision_function_shape='ovo', kernel='linear').fit(X_train, y_train)\n",
    "    svm_ovr_rbf = SVC(decision_function_shape='ovr', kernel='rbf').fit(X_train, y_train)\n",
    "    svm_ovr_rbf_gamma= SVC(decision_function_shape='ovr', kernel='rbf', gamma=0.005).fit(X_train, y_train)\n",
    "    svm_ovr_linear = SVC(decision_function_shape='ovr', kernel='linear').fit(X_train, y_train)\n",
    "    forest = RandomForestClassifier().fit(X_train, y_train)\n",
    "    \n",
    "    score_test_ovo_rbf = svm_ovo_rbf.score(X_test, y_test)\n",
    "    score_test_ovo_rbf_gamma = svm_ovo_rbf_gamma.score(X_test, y_test)\n",
    "    score_test_ovo_linear = svm_ovo_linear.score(X_test, y_test)\n",
    "    score_test_ovr_rbf = svm_ovr_rbf.score(X_test, y_test)\n",
    "    score_test_ovr_rbf_gamma = svm_ovr_rbf_gamma.score(X_test, y_test)\n",
    "    score_test_ovr_linear = svm_ovr_linear.score(X_test, y_test)\n",
    "    score_test_forest = forest.score(X_test, y_test)\n",
    "    \n",
    "    return [\n",
    "        score_test_ovo_rbf, \n",
    "        score_test_ovo_rbf_gamma, \n",
    "        score_test_ovo_linear, \n",
    "        score_test_ovr_rbf, \n",
    "        score_test_ovr_rbf_gamma, \n",
    "        score_test_ovr_linear,\n",
    "        score_test_forest\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d4a39",
   "metadata": {},
   "source": [
    "# Check score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "581c733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores = [\n",
    "    models(X_test, X_train, y_test, y_train),\n",
    "    models(X_test_fh, X_train_fh, y_test_fh, y_train_fh),\n",
    "    models(X_test_f[:,21:], X_train_f[:, 21:], y_test_f, y_train_f),\n",
    "    models(X_test_f, X_train_f, y_test_f, y_train_f)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e0efcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows (features):\n",
      "    1 - accelerometer_X, accelerometer_Y, accelerometer_Z\n",
      "    2 -  min_x, min_y, min_z, max_x, max_y, max_z, mean_x, mean_y, mean_z, std_x, std_y, std_z, median_x, median_y, median_z\n",
      "    3 -  skew_x, skew_y, skew_z, kurtosis_x, kurtosis_y, kurtosis_z, variance_x, variance_y, variance_z, correlation_x_y, correlation_x_z, correlation_y_z\n",
      "    4 -  min_x, min_y, min_z, max_x, max_y, max_z, mean_x, mean_y, mean_z, std_x, std_y, std_z, median_x, median_y, median_z, index_min_x, index_min_y, index_min_z, index_max_x, index_max_y, index_max_z, skew_x, skew_y, skew_z, kurtosis_x, kurtosis_y, kurtosis_z, variance_x, variance_y, variance_z, correlation_x_y, correlation_x_z, correlation_y_z\n",
      "\n",
      "       ovo rbf      ovo rbf gamma(0.005)     ovo linear           ovr rbf        ovr rbf gamma(0.005)     ovr linear         random forest   \n",
      "\n",
      "[0.8746130030959752, 0.8761609907120743, 0.8134674922600619, 0.8746130030959752, 0.8761609907120743, 0.8134674922600619, 0.8839009287925697]\n",
      "\n",
      "[0.9883900928792569, 0.9907120743034056, 0.9876160990712074, 0.9883900928792569, 0.9907120743034056, 0.9876160990712074, 1.0]\n",
      "\n",
      "[0.9729102167182663, 0.9852941176470589, 0.9798761609907121, 0.9729102167182663, 0.9852941176470589, 0.9798761609907121, 0.9969040247678018]\n",
      "\n",
      "[0.9744582043343654, 0.9690402476780186, 0.9930340557275542, 0.9744582043343654, 0.9690402476780186, 0.9930340557275542, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Rows (features):')\n",
    "print('    1 - accelerometer_X, accelerometer_Y, accelerometer_Z')\n",
    "print('    2 - ', ', '.join(features[:15]))\n",
    "print('    3 - ', ', '.join(features[21:]))\n",
    "print('    4 - ', ', '.join(features))\n",
    "print()\n",
    "print('       ovo rbf     ', \n",
    "      'ovo rbf gamma(0.005)', \n",
    "      '    ovo linear     ', \n",
    "      '     ovr rbf       ', \n",
    "      'ovr rbf gamma(0.005)', \n",
    "      '    ovr linear     ',\n",
    "      '   random forest   ')\n",
    "print()\n",
    "for el in result_scores:\n",
    "    print(el)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bad5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
